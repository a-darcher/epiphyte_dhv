{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Mock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import database.config as config\n",
    "import mock_data.mock_data_utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Generate Spike Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify seed information for mock spike trains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = 1\n",
    "session_nr = 1\n",
    "\n",
    "nr_units_patient_1 = 100\n",
    "begin_recording_time = 449860058000\n",
    "stop_recording_time =  455889058000\n",
    "nr_units_per_brain_region_1 = [7, 12, 9, 10, 15, 13, 8, 11, 12, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate mock spikes for one \"patient\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.generate_spikes(patient_id, session_nr, nr_units_patient_1, begin_recording_time, stop_recording_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Create Channel Names File\n",
    "\n",
    "Channels names indicate which brain region a given unit was recorded from. \n",
    "\n",
    "Here, channel files consist of a look-up table used to determine where a spike train originates. Once in the database, the region labels allow for dynamically switching between region-specific analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.generate_channel_file(patient_id, session_nr, nr_units_patient_1, nr_units_per_brain_region_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) and (4) Create Events File and timedDAQ log:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates mock Events.nev file, a proprietary file format from Neuralynx. \n",
    "\n",
    "Necessary for matching spike train data to stimulus information. \n",
    "\n",
    "In conjunction with the DAQ file, allows a linear mapping between the two different timescales (Neural recording device time and local computer time) so that neural events can be matched to stimulus evvents and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording length, in usec:  6029000000\n",
      "End time of recording, in epoch time:  1590534256608515\n",
      "Length of interval iteratively added:  1359413\n"
     ]
    }
   ],
   "source": [
    "utils.make_events_and_daq(patient_id, session_nr, begin_recording_time, stop_recording_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Create Watch Log File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same seed time as used for the timedDAQ file, generate a watchlog file for a given \"patient\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the stimulus, in usec:  4728999960.0\n",
      "End of stimulus, in epoch time:  1590532956608475.0\n",
      "Length of interval iteratively added :  37613\n"
     ]
    }
   ],
   "source": [
    "#utils.generate_perfect_watchlog(patient_id, session_nr)\n",
    "utils.generate_playback_artifacts(patient_id, session_nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat (1 - 4) for more \"patients\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording length, in usec:  6029000000\n",
      "End time of recording, in epoch time:  1590534256608515\n",
      "Length of interval iteratively added:  1277601\n",
      "Length of the stimulus, in usec:  4728999960.0\n",
      "End of stimulus, in epoch time:  1590532956608475.0\n",
      "Length of interval iteratively added :  37613\n"
     ]
    }
   ],
   "source": [
    "# Set seed info\n",
    "patient_id = 2\n",
    "session_nr = 1\n",
    "nr_units_patient_2 = 84 \n",
    "begin_recording_time = 349871349000\n",
    "stop_recording_time  = 355900349000\n",
    "nr_units_per_brain_region_2 = [12, 9, 10, 5, 7, 11, 8, 7, 12, 3]\n",
    "\n",
    "# Run generators\n",
    "utils.generate_spikes(patient_id, session_nr, nr_units_patient_2, begin_recording_time, stop_recording_time)\n",
    "utils.generate_channel_file(patient_id, session_nr, nr_units_patient_2, nr_units_per_brain_region_2)\n",
    "utils.make_events_and_daq(patient_id, session_nr, begin_recording_time, stop_recording_time)\n",
    "utils.generate_playback_artifacts(patient_id, session_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording length, in usec:  6029000000\n",
      "End time of recording, in epoch time:  1590534256608515\n",
      "Length of interval iteratively added:  1154980\n",
      "Length of the stimulus, in usec:  4728999960.0\n",
      "End of stimulus, in epoch time:  1590532956608475.0\n",
      "Length of interval iteratively added :  37613\n"
     ]
    }
   ],
   "source": [
    "# Set seed info\n",
    "patient_id = 3\n",
    "session_nr = 1\n",
    "nr_units_patient_3 = 59\n",
    "begin_recording_time = 248860058000\n",
    "stop_recording_time = 254889058000\n",
    "nr_units_per_brain_region_3 = [6, 5, 4, 6, 7, 10, 3, 7, 5, 6]\n",
    "\n",
    "# Run generators\n",
    "utils.generate_spikes(patient_id, session_nr, nr_units_patient_2, begin_recording_time, stop_recording_time)\n",
    "utils.generate_channel_file(patient_id, session_nr, nr_units_patient_2, nr_units_per_brain_region_2)\n",
    "utils.make_events_and_daq(patient_id, session_nr, begin_recording_time, stop_recording_time)\n",
    "utils.generate_playback_artifacts(patient_id, session_nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Create Stimulus Meta-Data \n",
    "\n",
    "For the purposes of demonstration, the meta-data consists of frames/movie time points in which a movie character was on-screen. \n",
    "\n",
    "Since the stimulus meta-data is taken only from the stimulus, this information only needs to be generated once per \"experimental\" paradigm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_movie_frames = 125725      # movie length: 5029 seconds (AVI file); 5029/0.04 = 125725\n",
    "perfect_pts = [round((x * 0.04), 2) for x in range(1, nr_movie_frames+1)]  \n",
    "\n",
    "annotator_ids = []\n",
    "for i in range(len(config.annotators)):\n",
    "    annotator_ids.append(config.annotators[i]['annotator_id'])\n",
    "\n",
    "path_to_movie_annotations = \"mock_data/movie_annotation\"\n",
    "\n",
    "if not os.path.exists(os.path.join(config.PATH_TO_REPO, path_to_movie_annotations)):\n",
    "    os.makedirs(os.path.join(config.PATH_TO_REPO, path_to_movie_annotations))\n",
    "\n",
    "nr_character_labels = 2\n",
    "\n",
    "start_times_1 = [0, 5000.04, 7000.04, 12000.04]\n",
    "stop_times_1 = [5000,7000,12000,12575]\n",
    "values_1 = [1,0,1,0]\n",
    "character1 = np.array([values_1, start_times_1, stop_times_1]) \n",
    "np.save(\"{}/{}/{}_character1_{}_20191212_character.npy\".format(\n",
    "    config.PATH_TO_REPO, path_to_movie_annotations, 1, random.choice(annotator_ids)), character1)\n",
    "\n",
    "\n",
    "start_times_2 = [0, 400.04, 4000.04, 10000.04, 10500.04]\n",
    "stop_times_2 = [400,4000,10000,10500,12575]\n",
    "values_2 = [0,1,0,1,0]\n",
    "character2 = np.array([values_2, start_times_2, stop_times_2]) \n",
    "np.save(\"{}/{}/{}_character2_{}_20191010_character.npy\".format(\n",
    "    config.PATH_TO_REPO, path_to_movie_annotations, 2, random.choice(annotator_ids)), character2)\n",
    "\n",
    "start_times_3 = [0, 100.04, 500.04]\n",
    "stop_times_3 = [100, 500, 12575]\n",
    "values_3 = [0,1,0]\n",
    "annot4 = np.array([values_3, start_times_3, stop_times_3]) \n",
    "np.save(\"{}/{}/{}_location1_{}_20200101_location.npy\".format(\n",
    "    config.PATH_TO_REPO, path_to_movie_annotations, 3, random.choice(annotator_ids)), annot4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
