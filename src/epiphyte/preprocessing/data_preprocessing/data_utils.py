#!/usr/bin/env python
# coding: utf-8

import numpy as np

NLX_OFFSET = 16 * 1024

nev_type = np.dtype([('', 'V6'),
                     ('timestamp', 'u8'),
                     ('id', 'i2'),
                     ('nttl', 'i2'),
                     ('', 'V38'),
                     ('ev_string', 'S128')])


def nev_read(filename):
    """
    Neuralynx .nev file reading function.
    Modified to accept npy binaries for generating mock data.
    Returns an array of timestamps and nttls.
    """

    if filename.lower().endswith((".nev")):
        eventmap = np.memmap(filename, dtype=nev_type, mode='r', offset=NLX_OFFSET)
        ret = np.array([eventmap['timestamp'], eventmap['nttl']]).T
    elif filename.lower().endswith((".npy")):
        ret = np.load(filename)
    return ret


def nev_string_read(filename):
    """
    Neuralynx .nev file reading function.
    Returns an array of timestamps and event strings.
    """
    eventmap = np.memmap(filename, dtype=nev_type, mode='r', offset=NLX_OFFSET)
    return np.array([eventmap['timestamp'], eventmap['ev_string']]).T


def process_movie_events(ev_array):

    wait_for = [1]
    last = 0
    keep = []

    for row in ev_array:
        code = row[1].astype(int)

        if code not in wait_for:
            continue

        elif code in [1, 2, 4, 8, 16, 32, 64, 128]:
            wait_for = [0]
            keep.append(row)

        elif code == 0:

            if last == 128:
                wait_for = [1]
            elif last in [1, 2, 4, 8, 16, 32, 64]:
                wait_for = [last * 2]

        last = code

    return np.array(keep)


def process_events(ev_array):

    if float(101) in ev_array[:, 1]:
        onsets = (ev_array[:, 1] == 101).nonzero()[0]
        n_101 = onsets.shape[0]

        # use the first 8 as marker that screening is over
        first_8 = (ev_array[:, 1] == 8).nonzero()[0][0]

        # go back to last 4 before first 8
        last_4 = (ev_array[:first_8, 1] == 4).nonzero()[0][-2]
        # print(first_8, last_4)

        assert n_101 in (4, 8)

        movie_events = ev_array[last_4 + 1:onsets[4], :]
        ret = process_movie_events(movie_events)

    elif not float(0) in ev_array[:,1]:
        ret = ev_array

    return ret


def getlines(filename):
    with open(filename, 'rb') as logfile:
        data = logfile.read()
    lines = data.splitlines()
    return lines


def read_watchlog(watchlogfile):
    """
    Extracts pts and real times.
    """
    lines = getlines(watchlogfile)
    pts = []
    time = []

    for line in lines[1:]:
        fields  = line.split()
        if len(fields) == 4:
            pts.append(float(fields[1]))
            time.append(int(fields[3]))

    pts = np.array(pts)
    time = np.array(time)
    return pts, time


def read_watchlog_pauses(watchlogfile):
    """
    Looks for movie playback pauses in the watchlog and retrieves timepoints corresponding to pause points. 
    
    Input: 
    watchlogfile: pts/cpu time watchlog from movie presentation (generated by mod-ffmpeg app)
    
    Outputs:
    start_time: float, cpu_time for a pause start 
    stop_time: float, cpu_time for a pause stop
    """
    lines = getlines(watchlogfile)
    start_time = []
    stop_time = []

    for i, line in enumerate(lines):
        fields = line.split()
        first = str(fields[0])
        # print(first)
        if "Pausing" in first:
            # print(line)
            start = i - 1
            start_line = lines[start]
            # print(start_line)
            start_fields = start_line.split()
            start_time.append(int(start_fields[3]))

        if "Continuing" in first:
            # print(line)
            stop = i + 1
            stop_line = lines[stop]
            stop_fields = stop_line.split()
            stop_time.append(int(stop_fields[3]))

        if "Properly" in first:
            start = i - 3
            start_line = lines[start]
            # print(start_line)
            start_fields = start_line.split()
            stop_time.append(int(start_fields[3]))

    return start_time, stop_time


def read_daqlog(daqlogfile):
    """
    Extracts the daq lines.
    """
    lines = getlines(daqlogfile)
    values = []
    pretime = []
    posttime = []

    for line in lines[3:]:
        fields = line.split()
        if len(fields) == 4:
            values.append(int(fields[0]))
            pretime.append(int(fields[2]))
            posttime.append(int(fields[3]))

    values = np.array(values)
    pretime = np.array(pretime)
    posttime = np.array(posttime)

    return values, pretime, posttime


def get_coeff(event_mat, daqlogfile):
    """ loads all the logs, checks and converts """
    eventTimes, eventValues = event_mat[:,0],event_mat[:,1]
    daqValues, daqPretimes, daqPosttimes = read_daqlog(daqlogfile)

    # check events:
    EventErrors = (eventValues != daqValues).sum()
    if EventErrors:
        raise(Warning('Events from 2 logs do not match, {} errors.'.
                      format(EventErrors)))

    # check that daq is quick enough
    diffs = daqPosttimes - daqPretimes
    print("Min Daq Diff: {:.1f} ms, Max Daq Diff: {:.1f} ms".
          format(diffs.min()/1e3, diffs.max()/1e3))

    # convert daqPosttimes to eventTimes by polyfit, check error
    m, b = np.polyfit(daqPosttimes, eventTimes, 1)
    fitdaq = m*daqPosttimes + b
    maxFitError = np.abs(fitdaq-eventTimes).max()/1e3

    print("Maximum Error after Event fit: {:.1f} ms".format(maxFitError))

    return np.array([m, b])


def make_msec(list_usec):
    """ convert a list-like from microseconds (default of event file)
            to milliseconds (default of recording sys)"""
    list_msec = [time / 1000 for i, time in enumerate(list_usec)]
    return list_msec


class TimeConversion(object):
    """
    Linearly maps between local computer time and the neural recording time, which 
    are on different timescales. 
    
    Allows the conversion of stimulus information (e.g., movie frame timestamps) to the spike time scale. 
    """
    
    def __init__(self, path_to_wl, path_to_dl, path_to_events):
        self.path_watchlog = path_to_wl
        self.path_daqlog = path_to_dl
        self.path_evts = path_to_events

    def convert(self):
        """
        Makes linear function for mapping from neural rec time to cpu time. 
        
        Outputs: 
        pts: presentation time stamps (frame times)
        daq_time: neural recording system time (dts)
        cpu_time: local laptop time (Unix epoch time)
        """
    
        event_mat = process_events(nev_read(self.path_evts))
        m, b = get_coeff(event_mat, self.path_daqlog)
        pts, cpu_time = read_watchlog(self.path_watchlog)
        
        # first convert cpu time to recording system time
        daq_time = cpu_time * m + b
        
        return pts, daq_time, cpu_time

    def convert_pauses(self):
        """
        Takes cpu_timestamps that correspond to a pause break in the movie playback, 
        and converts to neural recording time. 
        
        Could be accomplished also as a lookup table, but this just uses the 
        linear mapping itself.
        
        Outputs:
        convert_start: list, timestamps for the starts of pause breaks (neural-rec-time)
        convert_stop: list, corresponding timestamps for the stop of pause breaks (neural-rec-time)
        """
        start, stop = read_watchlog_pauses(self.path_watchlog)
        event_mat = process_events(nev_read(self.path_evts))
        m, b = get_coeff(event_mat, self.path_daqlog)

        convert_start = [time * m + b for i, time in enumerate(start)]
        convert_stop = [time * m + b for i, time in enumerate(stop)]
        
        #### NOTE: depending on the output set-up, comment/uncomment. 
        ##### Generally, can use the highlights options on the interactive plot
        ##### to indicate if time-scales are not coherent between the data and the 
        ##### pauses. 
        #convert_start = make_msec(convert_start)
        #convert_stop = make_msec(convert_stop)

        return convert_start, convert_stop


    def convert_skips(self):
        """
        Using the pts from the watchlog, this function checks for breaks in the otherwise continuous
        playback, and outputs the start and stop times in terms of neural recording time (DAQ). 
        """
        pts, daq_time, cpu_time = self.convert()
        
        threshold = 1
        max_jump = np.max(np.abs(np.diff(pts)))
        
        
        if max_jump >= threshold:
            print("There is a skip in the movie frame playback that is bigger than {} frames.\nThe biggest skip is {} frames.".format((threshold / 0.04), (max_jump / 0.04)))
            
            # list of indices where the pts jumped by 25+ frames
            beyond_threshold = np.where(np.abs(np.diff(pts)) > threshold)[0]
            print("Timepoints of skips, in neural_rec_time: {}".format(daq_time[beyond_threshold]))
            
            ## setting up start/stop values
            timepoints_of_skips = []
            timepoints_of_skips.append(daq_time[0]) # set first start point to the start of the rec_log

            for index in beyond_threshold:
                timepoints_of_skips.append(daq_time[index])
                timepoints_of_skips.append(daq_time[index + 1])

            timepoints_of_skips.append(daq_time[-1])
            
            ## specifying starts and stops from timepoint collection 
            start_values = timepoints_of_skips[0:-1:2]
            stop_values = timepoints_of_skips[1::2]
            values = np.array(range(0, len(start_values)))
            print("Start timepoints: {}".format(start_values))
            print("Stop timepoints: {}".format(stop_values))
            print("")
            
        else:
            print("There's not any skips in the movie frame playback that are bigger than {} frames.\nThe biggest skip is {} frames.".format((threshold / 0.04), (max_jump / 0.04)))
            print(" ")
            start_values = daq_time[0]
            stop_values = daq_time[-1]
            values = np.array([0])
        
        
        return start_values, stop_values, values
        